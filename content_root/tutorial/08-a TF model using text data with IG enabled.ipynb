{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Fiddler Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/app/fiddler_samples/samples/datasets/imdb_rnn/imdb_rnn.csv')\n",
    "df_schema = fdl.DatasetInfo.from_dataframe(df, max_inferred_cardinality=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A real blow-up of the film literally. This Bri...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I only wish that Return of the Jedi, have been...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"I like cheap perfume better; it doesn't last ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>On the eighth day God created Georges. But the...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No, this is not no Alice fairy tale my friends...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  polarity\n",
       "0  A real blow-up of the film literally. This Bri...     False\n",
       "1  I only wish that Return of the Jedi, have been...      True\n",
       "2  \"I like cheap perfume better; it doesn't last ...      True\n",
       "3  On the eighth day God created Georges. But the...      True\n",
       "4  No, this is not no Alice fairy tale my friends...      True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'imdb_rnn' not in client.list_datasets():\n",
    "    upload_result = client.upload_dataset(\n",
    "        dataset={'train': df}, \n",
    "        dataset_id='imdb_rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'polarity'\n",
    "feature_columns = ['sentence']\n",
    "train_input = df[feature_columns]\n",
    "train_target = df[target]\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info('imdb_rnn'),\n",
    "    target=target, \n",
    "    features=feature_columns,\n",
    "    display_name='Text IG',\n",
    "    description='this is a tensorflow model using text data and IG enabled from tutorial',\n",
    "    input_type=fdl.ModelInputType.TEXT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Tensorflow if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following line if you need to install Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_target = le.fit_transform(train_target)\n",
    "train_target = train_target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "vocab_size = 1000\n",
    "max_seq_length = 150\n",
    "tok = Tokenizer(num_words=vocab_size)\n",
    "tok.fit_on_texts(train_input['sentence'])\n",
    "sequences = tok.texts_to_sequences(train_input['sentence'])\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs', shape=[max_seq_length])\n",
    "    layer = Embedding(vocab_size, 64, input_length=max_seq_length)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256, name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(1, name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs, outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/leagenuit/opt/anaconda3/envs/fiddler/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/leagenuit/opt/anaconda3/envs/fiddler/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 150)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 64)           64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 113,921\n",
      "Trainable params: 113,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/leagenuit/opt/anaconda3/envs/fiddler/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "22500/22500 [==============================] - 18s 817us/sample - loss: 0.6660 - acc: 0.5887 - val_loss: 0.5008 - val_acc: 0.7616\n",
      "Epoch 2/5\n",
      "22500/22500 [==============================] - 17s 766us/sample - loss: 0.4221 - acc: 0.8160 - val_loss: 0.4245 - val_acc: 0.8088\n",
      "Epoch 3/5\n",
      "22500/22500 [==============================] - 17s 757us/sample - loss: 0.3724 - acc: 0.8448 - val_loss: 0.3524 - val_acc: 0.8480\n",
      "Epoch 4/5\n",
      "22500/22500 [==============================] - 17s 759us/sample - loss: 0.3549 - acc: 0.8520 - val_loss: 0.3649 - val_acc: 0.8380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c3ffc9810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model.fit(sequences_matrix, train_target, batch_size=128, epochs=5,\n",
    "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.rho\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: tf_ig_imdb/saved_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "import pickle\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "\n",
    "project_id = 'tutorial'\n",
    "model_id = 'tf_ig_imdb'\n",
    "\n",
    "# create temp dir\n",
    "model_dir = pathlib.Path(model_id)\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "model_dir.mkdir()\n",
    "\n",
    "# save model\n",
    "tf.keras.experimental.export_saved_model(model, str(model_dir / 'saved_model'))\n",
    "\n",
    "# save model schema\n",
    "with open(model_dir / 'model.yaml', 'w') as yaml_file:\n",
    "    yaml.dump({'model': model_info.to_dict()}, yaml_file)\n",
    "\n",
    "# save tokenizer\n",
    "with open(model_dir / 'tokenizer.pkl', 'wb') as tok_file:\n",
    "    tok_file.write(pickle.dumps(tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write package.py and related wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import 2 wrappers for tensorflow. Those files are stored in the utils directory.\n",
    "- The tf_saved_model_wrapper.py file contains a wrapper to load and run a TF model from a saved_model path.\n",
    "- The tf_saved_model_wrapper_ig.py file contains a wrapper to support Integrated Gradients (IG) computation for a TF model loaded from a saved_model path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['utils/tf_saved_model_wrapper.py', 'utils/tf_saved_model_wrapper_ig.py']\n",
    "for f in files:\n",
    "    shutil.copy(f, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write package.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to write the package.py file. This file contains functions to transform the input, generate the baseline and get the attributions.\n",
    "\n",
    "The project_attributions() function uses functionalities from the cover_tokens.py file that we need to write as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tf_ig_imdb/package.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_ig_imdb/package.py\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pathlib\n",
    "import pickle\n",
    "import logging\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from .tf_saved_model_wrapper_ig import TFSavedModelWrapperIg\n",
    "\n",
    "\n",
    "PACKAGE_PATH = pathlib.Path(__file__).parent\n",
    "SAVED_MODEL_PATH = PACKAGE_PATH / 'saved_model'\n",
    "TOKENIZER_PATH = PACKAGE_PATH / 'tokenizer.pkl'\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MyModel(TFSavedModelWrapperIg):\n",
    "    def __init__(self, saved_model_path, sig_def_key, tokenizer_path,\n",
    "                 target,\n",
    "                 is_binary_classification=False,\n",
    "                 output_key=None,\n",
    "                 batch_size=8,\n",
    "                 output_columns=[],\n",
    "                 input_tensor_to_differentiable_layer_mapping={},\n",
    "                 max_allowed_error=None):\n",
    "        \"\"\"\n",
    "        Class to load and run the IMDB RNN model.\n",
    "        See: TFSavedModelWrapper\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(saved_model_path, sig_def_key,\n",
    "                         is_binary_classification=is_binary_classification,\n",
    "                         output_key=output_key,\n",
    "                         batch_size=batch_size,\n",
    "                         output_columns=output_columns,\n",
    "                         input_tensor_to_differentiable_layer_mapping=\n",
    "                         input_tensor_to_differentiable_layer_mapping,\n",
    "                         max_allowed_error=max_allowed_error)\n",
    "        with open(tokenizer_path, 'rb') as handle:\n",
    "            self.tokenizer = pickle.load(handle)\n",
    "        self.max_seq_length = 150\n",
    "        self.target = target\n",
    "\n",
    "    def transform_input(self, input_df):\n",
    "        \"\"\"\n",
    "        Transform the provided dataframe into one that complies with the input\n",
    "        interface of the model.\n",
    "\n",
    "        Overrides the transform_input method of TFSavedModelWrapper.\n",
    "        \"\"\"\n",
    "        \n",
    "        sequences = self.tokenizer.texts_to_sequences(input_df[self.target])\n",
    "        sequences_matrix = sequence.pad_sequences(sequences,\n",
    "                                                  maxlen=self.max_seq_length,\n",
    "                                                  padding='post')\n",
    "\n",
    "        return pd.DataFrame({'inputs': sequences_matrix.tolist()})\n",
    "\n",
    "    def generate_baseline(self, input_df):\n",
    "        \n",
    "        input_tokens = input_df[self.target].apply(lambda x: '')\n",
    "        sequences = self.tokenizer.texts_to_sequences(input_tokens)\n",
    "        sequences_matrix = sequence.pad_sequences(sequences,\n",
    "                                                  maxlen=self.max_seq_length,\n",
    "                                                  padding='post')\n",
    "\n",
    "        return pd.DataFrame({'inputs': sequences_matrix.tolist()})\n",
    "\n",
    "    def project_attributions(self, input_df, transformed_input_df,\n",
    "                             attributions):\n",
    "        \"\"\"\n",
    "        Maps the transformed input to original input space so that the\n",
    "        attributions correspond to the features of the original input.\n",
    "        Overrides the project_attributions method of TFSavedModelWrapper.\n",
    "        \"\"\"\n",
    "        segments = re.split(r'([ '+self.tokenizer.filters+'])', input_df[self.target].iloc[0])\n",
    "        unpadded_input=[self.tokenizer.texts_to_sequences([x])[0] for x in input_df[self.target].values]\n",
    "        word_tokens = self.tokenizer.sequences_to_texts([[x] for x in unpadded_input[0]])\n",
    "        word_attributions = attributions['inputs'][0].astype('float').tolist()[:len(word_tokens)] \n",
    "        \n",
    "        # Let's walk segments and assign attributions to the components where\n",
    "        # they match word_tokens, the token sequence consumed by the model; otherwise assign 0.\n",
    "        i = 0\n",
    "        final_attributions = []\n",
    "        final_segments = []\n",
    "        for segment in segments:\n",
    "            if segment is not '':\n",
    "                final_segments.append(segment)\n",
    "                seg_low = segment.lower()\n",
    "                if len(word_tokens)>i and seg_low == word_tokens[i]:\n",
    "                    final_attributions.append(word_attributions[i])\n",
    "                    i+=1\n",
    "                else:\n",
    "                    final_attributions.append(0)       \n",
    "        return {\"embedding_input\":[final_segments, final_attributions]}\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = MyModel(\n",
    "        SAVED_MODEL_PATH,\n",
    "        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY,\n",
    "        TOKENIZER_PATH,\n",
    "        target='sentence',\n",
    "        is_binary_classification=True,\n",
    "        batch_size=128,\n",
    "        output_columns=['inputs'],\n",
    "        input_tensor_to_differentiable_layer_mapping=\n",
    "        {'inputs': 'embedding/embedding_lookup:0'},\n",
    "        max_allowed_error=5)\n",
    "    model.load_model()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_model(project_id, model_id)\n",
    "client.upload_model_package(model_dir, project_id, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.213811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.643106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.302248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.382934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.111019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     inputs\n",
       "0  0.213811\n",
       "1  0.643106\n",
       "2  0.219616\n",
       "3  0.388280\n",
       "4  0.302248\n",
       "5  0.382934\n",
       "6  0.144117\n",
       "7  0.093723\n",
       "8  0.077600\n",
       "9  0.111019"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_input = train_input[:10]\n",
    "result = client.run_model(project_id, model_id, prediction_input)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_point = df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'tutorial'\n",
    "model_id = 'tf_ig_imdb'\n",
    "\n",
    "ex_ig = client.run_explanation(\n",
    "    project_id=project_id,\n",
    "    model_id=model_id, \n",
    "    df=selected_point, \n",
    "    dataset_id='imdb_rnn',\n",
    "    explanations='ig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttributionExplanation(algorithm='ig', inputs=['A', ' ', 'real', ' ', 'blow', '-', 'up', ' ', 'of', ' ', 'the', ' ', 'film', ' ', 'literally', '.', ' ', 'This', ' ', 'British', ' ', 'film', ' ', 'is', ' ', 'boringly', ' ', 'made', '.', '<', 'br', ' ', '/', '>', '<', 'br', ' ', '/', '>', 'What', ' ', 'an', ' ', 'exciting', ' ', 'plot', '!', ' ', 'A', ' ', 'terrorist', ' ', 'places', ' ', 'bombs', ' ', 'on', ' ', 'a', ' ', 'train', '.', ' ', 'How', ' ', 'could', ' ', 'the', ' ', 'writers', ' ', 'and', ' ', 'producers', ' ', 'of', ' ', 'this', ' ', 'stinker', ' ', 'turn', ' ', 'this', ' ', 'into', ' ', 'such', ' ', 'a', ' ', 'dull', ' ', 'story', '?', '<', 'br', ' ', '/', '>', '<', 'br', ' ', '/', '>', 'Glenn', ' ', 'Ford', ',', ' ', 'as', ' ', 'the', ' ', 'expert', ' ', 'called', ' ', 'upon', ' ', 'to', ' ', 'defuse', ' ', 'the', ' ', 'bomb', ',', ' ', 'is', ' ', 'given', ' ', 'awful', ' ', 'writing', ' ', 'material', ' ', 'to', ' ', 'work', ' ', 'with', '.', ' ', 'Naturally', ',', ' ', 'just', ' ', 'as', ' ', 'he', ' ', 'is', ' ', 'called', ' ', 'in', ',', ' ', 'his', ' ', 'wife', ',', ' ', 'Anne', ' ', 'Vernon', ',', ' ', 'is', ' ', 'about', ' ', 'to', ' ', 'leave', ' ', 'him', '.', ' ', 'No', ' ', 'wonder', ' ', 'we', ' ', 'never', ' ', 'heard', ' ', 'of', ' ', 'Miss', ' ', 'Vernon', '.', ' ', 'After', ' ', 'such', ' ', 'a', ' ', 'film', ',', ' ', 'it', ' ', 'would', ' ', 'be', ' ', 'enough', ' ', 'to', ' ', 'end', ' ', 'her', ' ', 'career', '.', '<', 'br', ' ', '/', '>', '<', 'br', ' ', '/', '>', 'That', ' ', 'elderly', ' ', 'man', ' ', 'who', ' ', 'loved', ' ', 'trains', ' ', 'and', ' ', 'interferes', ' ', 'is', ' ', 'our', ' ', '1953', ' ', 'version', ' ', 'of', ' ', 'senile', ' ', 'dementia', '.', ' ', 'I', ' ', 'thought', ' ', 'it', ' ', 'was', ' ', 'highly', ' ', 'insulting', ' ', 'to', ' ', 'show', ' ', 'this', ' ', 'man', ',', ' ', 'even', ' ', 'at', ' ', 'the', ' ', 'end', '.'], attributions=[-0.0006829905323684216, 0, 0.003395126201212406, 0, 0, 0, -0.0023579830303788185, 0, -0.0014940391993150115, 0, 0.00139651820063591, 0, 0.004431116860359907, 0, 0, 0, 0, -0.0053215837106108665, 0, 0.005699655972421169, 0, 0.004355758894234896, 0, 0.0027883751317858696, 0, 0, 0, -0.0012899141293019056, 0, 0, -0.0026434329338371754, 0, 0, 0, 0, -0.002669696928933263, 0, 0, 0, 0.007054252550005913, 0, -0.003704848699271679, 0, 0, 0, -0.015978947281837463, 0, 0, -0.0005900260293856263, 0, 0, 0, 0, 0, 0, 0, -0.0065615298226475716, 0, -0.0005221441388130188, 0, 0, 0, 0, 0.0015703646931797266, 0, -0.0032446924597024918, 0, 0.0015183779178187251, 0, -0.012322455644607544, 0, 0.004749790765345097, 0, 0, 0, -0.001671741483733058, 0, -0.006333973258733749, 0, 0, 0, -0.005919535644352436, 0, -0.006571135018020868, 0, -0.003648888086900115, 0, -9.942043107002974e-05, 0, -0.00011563784210011363, 0, -0.09481218457221985, 0, 0.006018005311489105, 0, 0, -0.0029055364429950714, 0, 0, 0, 0, -0.002922146115452051, 0, 0, 0, 0, 0, 0, 0, 0, 0.0029131812043488026, 0, 0.002366510918363929, 0, 0, 0, -0.009063517674803734, 0, -0.0040375166572630405, 0, -0.0023412094451487064, 0, 0, 0, 0.002389343921095133, 0, 0, 0, 0, 0.003328109858557582, 0, -0.005065121687948704, 0, -0.12852726876735687, 0, -0.022253774106502533, 0, -0.040489811450242996, 0, -0.002252192236483097, 0, 0.003254897892475128, 0, -0.00020041957031935453, 0, 0, 0, 0, 0, -0.012139000929892063, 0, 0.0040110754780471325, 0, 0.009146705269813538, 0, 0.0046216147020459175, 0, -0.009575456380844116, 0, 0.00033986219204962254, 0, 0, 0.0038569639436900616, 0, -0.006320911925286055, 0, 0, 0, 0, 0, 0, 0, 0.004734093323349953, 0, 0.0018987680086866021, 0, -0.002408361993730068, 0, 0.0010679666884243488, 0, 0.00966392271220684, 0, 0, -0.02524000220000744, 0, -0.05100337415933609, 0, 0.00676826573908329, 0, 0.0035210815258324146, 0, 0.006509467028081417, 0, -0.0006908990908414125, 0, 0.008573047816753387, 0, 0, 0, 0, -0.002348187379539013, 0, 0.001150732859969139, 0, 0.002625248394906521, 0, 0.0045159077271819115, 0, 0, 0.012234115041792393, 0, -0.014023798517882824, 0, -0.00022541219368577003, 0, -0.0288243405520916, 0, -0.002540161367505789, 0, -0.002982703037559986, 0, 0.007068790029734373, 0, -0.011724356561899185, 0, 0, -0.0019753880333155394, 0, 0, 0, 0, -0.0019365636399015784, 0, 0, 0, 0.004856598563492298, 0, 0, 0, 0.00752157811075449, 0, 0.005203995853662491, 0, 0.07405169308185577, 0, 0, 0, 0.011350235901772976, 0, 0, 0, 0.0070631662383675575, 0, 0.021599197760224342, 0, 0, 0, -0.01680898480117321, 0, -0.0005599972791969776, 0, 0, 0, 0, 0, 0, 0.00480162538588047, 0, 0.017722120508551598, 0, 0.015216683968901634, 0, -0.0060071786865592, 0, 0.10369651019573212, 0, 0, 0, -0.0031018583104014397, 0, 0.011227262206375599, 0, -0.010566869750618935, 0, 0.007650124840438366, 0, 0, -0.03887499123811722, 0, 0.0008381765801459551, 0, 0.004690284840762615, 0, -0.004404568579047918, 0], misc={'explanation': {}})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
