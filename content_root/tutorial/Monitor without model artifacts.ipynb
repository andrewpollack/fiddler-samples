{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load prediction log\n",
    "\n",
    "Prediction logs must contains the models input features and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prediction_log_df = pd.read_csv('/app/fiddler_samples/samples/datasets/p2p_loans/p2p_production.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup/cleanup project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'tutorial'\n",
    "model_id = 'test4'\n",
    "\n",
    "if project_id in client.list_projects():\n",
    "    client.delete_model(project_id, model_id)\n",
    "    client.delete_dataset(model_id)\n",
    "else:\n",
    "    client.create_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model from prediction log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating inputs ...\n",
      "Uploading dataset ...\n",
      "Setting up monitoring without model artifact ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Monitoring successfully setup on Fiddler. \\n Visit http://localhost:4100/projects/tutorial to monitor'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = ['probability_fully_paid']\n",
    "\n",
    "is_feature = lambda x: x not in outputs\n",
    "features = list(filter(is_feature, list(prediction_log_df.columns)))\n",
    "\n",
    "client.create_model_from_prediction_log(\n",
    "    project_id,\n",
    "    model_id,\n",
    "    prediction_log_df,\n",
    "    features,\n",
    "    outputs,\n",
    "    model_task=fdl.ModelTask.BINARY_CLASSIFICATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send monitoring events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending 104 / 2997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-aad15962813f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Sending {count} / {len(prediction_log_df)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "two_weeks_ms = 604800 * 2 * 1000\n",
    "\n",
    "chunked_df = [prediction_log_df[i:i+1] for i in range(0, prediction_log_df.shape[0], 1)]\n",
    "count = 0\n",
    "for row_df in chunked_df:\n",
    "    data = row_df.to_dict('records')[0]\n",
    "    occurred_at = int(round(time.time() * 1000)) - random.randint(0, two_weeks_ms)\n",
    "\n",
    "    result = client.publish_event(project_id, model_id, data, event_time_stamp=occurred_at)\n",
    "    \n",
    "    count += 1\n",
    "    clear_output(wait = True)\n",
    "    print(f'Sending {count} / {len(prediction_log_df)}')\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
