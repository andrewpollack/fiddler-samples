{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "import logging\n",
    "\n",
    "# True for logging debug message \n",
    "verbose = True\n",
    "\n",
    "if verbose:\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "client = fdl.FiddlerApi(verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/app/fiddler_samples/samples/datasets/winequality/train.csv')\n",
    "df_schema = fdl.DatasetInfo.from_dataframe(df, max_inferred_cardinality=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'wine_quality' not in client.list_datasets():\n",
    "    upload_result = client.upload_dataset(\n",
    "        dataset={'train': df}, \n",
    "        dataset_id='wine_quality')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create model schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'quality'\n",
    "train_input = df.drop(columns=['row_id', 'quality'])\n",
    "train_target = df[target]\n",
    "\n",
    "feature_columns = list(train_input.columns)\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info('wine_quality'),\n",
    "    target=target, \n",
    "    features=feature_columns,\n",
    "    display_name='debug model',\n",
    "    description='this is a sklearn model from tutorial that shows how to debug model upload'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "full_model = sklearn.pipeline.Pipeline(steps=[\n",
    "        ('standard_scaling', sklearn.preprocessing.StandardScaler()),\n",
    "        ('model_name', regressor),\n",
    "    ])\n",
    "\n",
    "full_model.fit(train_input, train_target)\n",
    "full_model.predict(train_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "project_id = 'tutorial'\n",
    "model_id = 'debug_model'\n",
    "\n",
    "# create temp dir\n",
    "model_dir = pathlib.Path(model_id)\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "model_dir.mkdir()\n",
    "\n",
    "# save model\n",
    "with open(model_dir / 'model.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(full_model, pkl_file)\n",
    "\n",
    "# save model schema\n",
    "with open(model_dir / 'model.yaml', 'w') as yaml_file:\n",
    "    yaml.dump({'model': model_info.to_dict()}, yaml_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write package.py wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile debug_model/package.py\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import logging\n",
    "from flask import Flask, request\n",
    "\n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "\n",
    "class SklearnModelPackage:\n",
    "    is_classifier = False\n",
    "    output_columns = ['predicted_quality']\n",
    "\n",
    "    def __init__(self):\n",
    "        with open(PACKAGE_PATH / 'model.pkl', 'rb') as infile:\n",
    "            self.model = pickle.load(infile)\n",
    "\n",
    "    def predict(self, input_df):\n",
    "        # this will log the row request coming in to the server\n",
    "        logging.info(f'log raw request {request.data}')\n",
    "        \n",
    "        # this will log the dataframe after transforming\n",
    "        logging.info(f'log dataframe {input_df}')\n",
    "        f = self.model.predict if not self.is_classifier else self.model.predict_proba\n",
    "        return pd.DataFrame(f(input_df), columns=self.output_columns)\n",
    "    \n",
    "def get_model():\n",
    "    return SklearnModelPackage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show generated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l debug_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test package.py locally before uploading\n",
    "You may have to restart the kernel for the class to be loaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def my_import(name):\n",
    "    components = name.split('.')\n",
    "    mod = __import__(components[0])\n",
    "    for comp in components[1:]:\n",
    "        mod = getattr(mod, comp)\n",
    "    return mod\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "model_class = my_import('debug_model.package')\n",
    "reload(model_class)\n",
    "\n",
    "model_class.get_model().predict(train_input[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_model(project_id, model_id)\n",
    "client.upload_model_package(model_dir, project_id, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input = train_input[0: 10]\n",
    "result = client.run_model(project_id, model_id, prediction_input, log_events=True)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
