{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring with No Model [Basic]\n",
    "For this section, we will cover how to begin monitoring with only a prediction\n",
    "log. We will do so by sending monitoring events for a specific model and \n",
    "project we configure.\n",
    "\n",
    "Specifically, we will:\n",
    "- Initialize a connection with Fiddler\n",
    "- Load a prediction log\n",
    "- Create a project\n",
    "- Create a model using the prediction log\n",
    "- Send monitoring events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n",
    "We begin this section as usual by establishing a connection to our\n",
    "Fiddler instance. We can establish this connection either by specifying \n",
    "our credentials directly, or by utilizing our `fiddler.ini` file. More\n",
    "information can be found in the [setup](https://github.com/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/00%20Setup.ipynb) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "\n",
    "# client = fdl.FiddlerApi(url=url, org_id=org_id, auth_token=auth_token)\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Prediction Log\n",
    "\n",
    "Prediction logs must contains the model's input features and predictions. This is information\n",
    "that can be collected while a model is running in production. For this demonstration, we have\n",
    "collected events and saved them in a file called `p2p_production.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prediction_log_df = pd.read_csv('/app/fiddler_samples/samples/datasets/p2p_loans/p2p_production.log')\n",
    "prediction_log_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Project\n",
    "Projects are one of the key entities of Fiddler. They are convenient containers \n",
    "for housing the models and datasets associated with a given ML use case. Specifics about\n",
    "projects can be found [here](https://docs.fiddler.ai/components/#project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'tutorial'\n",
    "model_id = 'no_model_artifact'\n",
    "\n",
    "if project_id in client.list_projects():\n",
    "    client.delete_model(project_id, model_id)\n",
    "    client.delete_dataset(model_id)\n",
    "else:\n",
    "    client.create_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Using Prediction Log\n",
    "With our project now created, we will now create a model using the prediction log.\n",
    "Models are another one of the key entities of Fiddler, and we will create \n",
    "this model will be used for generating relevant schema information. More \n",
    "information about models can be found [here](https://docs.fiddler.ai/components/#model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outputs = ['probability_fully_paid']\n",
    "\n",
    "is_feature = lambda x: x not in outputs\n",
    "features = list(filter(is_feature, list(prediction_log_df.columns)))\n",
    "\n",
    "client.create_model_from_prediction_log(\n",
    "    project_id,\n",
    "    model_id,\n",
    "    prediction_log_df,\n",
    "    features,\n",
    "    outputs,\n",
    "    model_task=fdl.ModelTask.BINARY_CLASSIFICATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Monitoring Events\n",
    "In this step, we will be simulating traffic to send for our model monitoring by using \n",
    "[publish_event](https://docs.fiddler.ai/api-reference/python-package/#publish-event). \n",
    "This will be the equivalent of running our model separately on data, and either \n",
    "sending to Fiddler then, or saving this information to a log and sending at a later point.\n",
    "\n",
    "For this demonstration, we will be going with a log-related approach. \n",
    "This log contains rows that have inputs and predictions. \n",
    "To most accurately simulate this as a time-series event, we will also be calling \n",
    "a function to generate a timestamp in the last two weeks. Real data will ideally \n",
    "have a timestamp related to when the event took place; otherwise, the current \n",
    "time will be used.\n",
    "\n",
    "**Note**: The timestamp must be in UTC milliseconds. See \n",
    "[here](https://docs.fiddler.ai/api-reference/python-package/#publish-event) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from random import sample, randint\n",
    "NUM_EVENTS_TO_SEND = 50\n",
    "\n",
    "def getTimestampFromPastTwoWeeks():\n",
    "    \"\"\"\n",
    "    Generate a randomized timestamp from the past two weeks. Timestamp is in \n",
    "    milliseconds since epoch in UTC.\n",
    "    \"\"\"\n",
    "    TWO_WEEKS_MS = 604800 * 2 * 1000\n",
    "    current_time_in_ms = round(time.time() * 1000)\n",
    "    \n",
    "    random_time_in_past_two_weeks = current_time_in_ms - randint(0, TWO_WEEKS_MS)\n",
    "    return random_time_in_past_two_weeks\n",
    "\n",
    "# Convert this dataframe into a list of dictionary events, where each event is its own dictionary\n",
    "event_list_dict = prediction_log_df.sample(n=NUM_EVENTS_TO_SEND, random_state=42).to_dict(orient='records') \n",
    "\n",
    "for ind, event_dict in enumerate(event_list_dict):\n",
    "    event_ms_time_stamp = getTimestampFromPastTwoWeeks()\n",
    "    result = client.publish_event(project_id, model_id, event_dict, event_time_stamp=event_ms_time_stamp)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    readable_timestamp = datetime.datetime.fromtimestamp(event_ms_time_stamp/1000.0)\n",
    "    \n",
    "    print(f'Sending {ind+1} / {NUM_EVENTS_TO_SEND} \\n{readable_timestamp} UTC: \\n{event_dict}')\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
