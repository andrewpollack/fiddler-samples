{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Monitoring with Surrogate Model\n",
    "\n",
    "This tutorial shows how to use Model Monitoring in Fiddler if you only have a Dataset \n",
    "and no model artifacts. The tutorial has two parts, part one is to upload your dataset \n",
    "and use Fiddler's surrogate model capability to generate a model and part two is to ingest \n",
    "the monitoring events using `publish_event` API and use the surrogate model to monitor \n",
    "your production traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n",
    "We begin this section as usual by establishing a connection to our\n",
    "Fiddler instance. We can establish this connection either by specifying \n",
    "our credentials directly, or by utilizing our `fiddler.ini` file. More\n",
    "information can be found in the [setup](https://github.com/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/00%20Setup.ipynb) section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "\n",
    "# client = fdl.FiddlerApi(url=url, org_id=org_id, auth_token=auth_token)\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will load in our baseline dataset from a csv called `p2p_loans.csv`. We will\n",
    "also create a schema using this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline_df = pd.read_csv('/app/fiddler_samples/samples/datasets/p2p_loans/p2p_loans.csv')\n",
    "baseline_schema = fdl.DatasetInfo.from_dataframe(baseline_df, max_inferred_cardinality=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Monitoring Using Surrogate Model\n",
    "Now, we will setup a project, and use Fiddler's surrogate model capability to generate a model. \n",
    "Projects are one of the key entities of Fiddler. They are convenient containers \n",
    "for housing the models and datasets associated with a given ML use case. Specifics about\n",
    "projects can be found [here](https://docs.fiddler.ai/components/#project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating inputs ...\n",
      "Uploading dataset ...\n",
      "Generating surrogate model ...\n",
      "Triggering model predictions ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Surrogate model successfully setup on Fiddler. \\n Visit http://localhost:4100/projects/tutorial '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id = 'tutorial'\n",
    "model_id = 'loan_status_surrogate'\n",
    "target='loan_status'\n",
    "features = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_range_low', 'total_acc', 'acc_open_past_24mths']\n",
    "\n",
    "## setup/cleanup project\n",
    "if project_id in client.list_projects():\n",
    "    client.delete_model(project_id, model_id)\n",
    "    client.delete_dataset(model_id)\n",
    "else:\n",
    "    client.create_project(project_id)\n",
    "\n",
    "\n",
    "client.create_surrogate_model(\n",
    "    project_id,\n",
    "    model_id,\n",
    "    baseline_df,\n",
    "    baseline_schema,\n",
    "    target,\n",
    "    features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Monitoring Events\n",
    "In this step, we will be simulating traffic to send for our model monitoring by using \n",
    "[publish_event](https://docs.fiddler.ai/api-reference/python-package/#publish-event). \n",
    "This will be the equivalent of running our model separately on data, and either \n",
    "sending to Fiddler then, or saving this information to a log and sending at a later point.\n",
    "\n",
    "For this demonstration, we will be going with a log-related approach. \n",
    "This log, `p2p_production.log` will contains rows that have inputs and predictions. \n",
    "To most accurately simulate this as a time-series event, we will also be calling \n",
    "a function to generate a timestamp in the last two weeks. Real data will ideally \n",
    "have a timestamp related to when the event took place; otherwise, the current \n",
    "time will be used.\n",
    "\n",
    "**Note**: The timestamp must be in UTC milliseconds. See \n",
    "[here](https://docs.fiddler.ai/api-reference/python-package/#publish-event) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending 50 / 50 \n",
      "2020-12-08 09:39:26.685000 UTC: \n",
      "{'loan_amnt': 25925, 'int_rate': 6.99, 'annual_inc': 160000.0, 'dti': 12.99, 'fico_range_low': 675, 'total_acc': 17, 'acc_open_past_24mths': 4, 'probability_fully_paid': 0.893918146366147, '__event_type': 'execution_event', '__occurred_at': 1607420366685}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from random import sample, randint\n",
    "NUM_EVENTS_TO_SEND = 50\n",
    "\n",
    "def getTimestampFromPastTwoWeeks():\n",
    "    \"\"\"\n",
    "    Generate a randomized timestamp from the past two weeks. Timestamp is in \n",
    "    milliseconds since epoch in UTC.\n",
    "    \"\"\"\n",
    "    TWO_WEEKS_MS = 604800 * 2 * 1000\n",
    "    current_time_in_ms = round(time.time() * 1000)\n",
    "    \n",
    "    random_time_in_past_two_weeks = current_time_in_ms - randint(0, TWO_WEEKS_MS)\n",
    "    return random_time_in_past_two_weeks\n",
    "\n",
    "result_df = pd.read_csv('/app/fiddler_samples/samples/datasets/p2p_loans/p2p_production.log')\n",
    "# Convert this dataframe into a list of dictionary events, where each event is its own dictionary\n",
    "event_list_dict = result_df.sample(n=NUM_EVENTS_TO_SEND, random_state=42).to_dict(orient='records') \n",
    "\n",
    "for ind, event_dict in enumerate(event_list_dict):\n",
    "    event_ms_time_stamp = getTimestampFromPastTwoWeeks()\n",
    "    result = client.publish_event(project_id, model_id, event_dict, event_time_stamp=event_ms_time_stamp)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    readable_timestamp = datetime.datetime.fromtimestamp(event_ms_time_stamp/1000.0)\n",
    "    \n",
    "    print(f'Sending {ind+1} / {NUM_EVENTS_TO_SEND} \\n{readable_timestamp} UTC: \\n{event_dict}')\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
